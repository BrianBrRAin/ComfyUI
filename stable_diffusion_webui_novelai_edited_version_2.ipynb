{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 4325487,
          "sourceType": "datasetVersion",
          "datasetId": 2545502
        },
        {
          "sourceId": 4483481,
          "sourceType": "datasetVersion",
          "datasetId": 2623525
        },
        {
          "sourceId": 4599564,
          "sourceType": "datasetVersion",
          "datasetId": 2642097
        },
        {
          "sourceId": 4644458,
          "sourceType": "datasetVersion",
          "datasetId": 2699847
        },
        {
          "sourceId": 4661756,
          "sourceType": "datasetVersion",
          "datasetId": 2641953
        },
        {
          "sourceId": 4769045,
          "sourceType": "datasetVersion",
          "datasetId": 2751154
        },
        {
          "sourceId": 4868565,
          "sourceType": "datasetVersion",
          "datasetId": 2816291
        },
        {
          "sourceId": 4878107,
          "sourceType": "datasetVersion",
          "datasetId": 2817348
        },
        {
          "sourceId": 4890412,
          "sourceType": "datasetVersion",
          "datasetId": 2835742
        },
        {
          "sourceId": 4896492,
          "sourceType": "datasetVersion",
          "datasetId": 2839504
        },
        {
          "sourceId": 4931739,
          "sourceType": "datasetVersion",
          "datasetId": 2859894
        },
        {
          "sourceId": 4931757,
          "sourceType": "datasetVersion",
          "datasetId": 2859904
        },
        {
          "sourceId": 4931814,
          "sourceType": "datasetVersion",
          "datasetId": 2859939
        },
        {
          "sourceId": 4937465,
          "sourceType": "datasetVersion",
          "datasetId": 2701328
        },
        {
          "sourceId": 4988923,
          "sourceType": "datasetVersion",
          "datasetId": 2716934
        },
        {
          "sourceId": 4992711,
          "sourceType": "datasetVersion",
          "datasetId": 2895798
        },
        {
          "sourceId": 5032397,
          "sourceType": "datasetVersion",
          "datasetId": 2920659
        },
        {
          "sourceId": 5036765,
          "sourceType": "datasetVersion",
          "datasetId": 2859442
        },
        {
          "sourceId": 5047046,
          "sourceType": "datasetVersion",
          "datasetId": 2701284
        },
        {
          "sourceId": 5071735,
          "sourceType": "datasetVersion",
          "datasetId": 2856823
        },
        {
          "sourceId": 6817788,
          "sourceType": "datasetVersion",
          "datasetId": 3074484
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrianBrRAin/ComfyUI/blob/main/stable_diffusion_webui_novelai_edited_version_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## NovelAi Stable Diffusion - webui +API AI绘画项目 SD云部署\n",
        "**torch: 2.0.1+cu118  •  xformers: 0.0.21**\n",
        "\n",
        "**创建日期：2022年11月18日**\n",
        "\n",
        "**上次更新：2023年11月23日**\n",
        "## <span style=\"color:red; font-weight:bold;\"> 全网唯一全免费SD云端部署平台</span>\n",
        "## [使用教程(视频)](https://www.bilibili.com/video/BV1b34y1N7Sf/?spm_id_from=333.999.0.0)\n",
        "## [使用教程(文章)[部分内容已过时]](https://zhuanlan.zhihu.com/p/659394256)\n",
        "## [发布地址](https://www.kaggle.com/code/qq2575044704/stable-diffusion-webui-novelai-edited-version-2)\n",
        "<!---\n",
        "这里是作者的署名和群号码，未经同意请勿删除，删一句家里人少一个\n",
        "--->\n",
        "<!---\n",
        "倒卖狗全家死光\n",
        "--->\n"
      ],
      "metadata": {
        "id": "5sWRw8GCZM-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 请先看使用教程！如果你是手机端请用Edge浏览器并且调成电脑版UI\n",
        "> ## 使用方法：使用Run All或者Save Version运行，从内网穿透链接进入WebUI\n",
        "![image.png](attachment:a958cdd4-ac25-4b31-be41-4398b9df625e.png)"
      ],
      "metadata": {
        "id": "hsJwnFWIZM-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ai绘画模型站：\n",
        "## [Civitai](http://civitai.com) （C站）\n",
        "\n",
        "### [huggingface](http://huggingface.co)\n",
        "## 未经同意禁止将源代码用于出售，一经发现必定追究\n",
        "## **使用前请注意：**\n",
        "> * ### kaggle每周提供了免费的GPU，但请不要滥用免费资源\n",
        "\n",
        "> * Kaggle provides 30h GPU per week, but please do not abuse free resources\n",
        "\n",
        "> * ### 不建议生成违返法律的图片【尽可能避开违禁词】。\n",
        "\n",
        "> * do not generate images that against the kaggle rules。\n",
        "\n",
        "> * ### 如果报错了，不妨重新看一遍教程\n",
        "\n",
        "> * I didn't make a English version of this notebook, If you are English user, you will probably need a translator. and learn how to use this\n",
        "<!---\n",
        "这里是作者的署名和群号码，未经同意请勿删除，删一句家里人少一个\n",
        "--->\n",
        "<!---\n",
        "倒卖狗全家死光\n",
        "--->"
      ],
      "metadata": {
        "id": "upVJayuKZM-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "APJ5Tco9ZM-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\"> Webui基础配置(可改也可不改) </span>"
      ],
      "metadata": {
        "id": "NebOGxZ3ZM-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# True 表示是 ， False 表示否\n",
        "# 安装目录\n",
        "install_path=\"/kaggle/working\" #或者/kaggle\n",
        "updata_webui = False  #是否开机自动更新webui\n",
        "\n",
        "# 重置变量 会删掉sd_webui重新安装\n",
        "reLoad = True\n",
        "updata_webui = True\n",
        "\n",
        "#清理和打包生成的图片\n",
        "zip_output=True\n",
        "clear_output=False\n",
        "#打包环境减少下次启动时\n",
        "use_zip_venv = False\n",
        "\n",
        "\n",
        "# 使用huggingface保存和载入webui配置文件\n",
        "huggingface_use = True\n",
        "huggingface_token_file = '/kaggle/input/tenkens/hugfacetoken.txt'\n",
        "huggiingface_repo_id = 'ACCA225/sd-configs-4'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.643439Z",
          "iopub.execute_input": "2023-10-25T07:50:23.643806Z",
          "iopub.status.idle": "2023-10-25T07:50:23.657740Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.643777Z",
          "shell.execute_reply": "2023-10-25T07:50:23.656636Z"
        },
        "trusted": true,
        "id": "ZnvnrFqpZM-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "0lv7okP0ZM-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">插件，模型地址 （添加模型在此代码单元格修改）</span>‘\n",
        "## <span style=\"color:red; font-weight:bold;\">上传模型方法见顶部的教程，C站获取下载链接方法：在模型下载处右键，手机端用户长按下载按钮，复制地址即可</span>\n",
        "## <span style=\"color:red; font-weight:bold;\">如果模型数量较多，可选用上传到kaggle数据集方法来载入模型</span>\n",
        "## 现在可以使用自定义模型文件名了！格式：['a.safetensors:b'] 其中a.safetensor为文件名，b为下载链接，用冒号隔开"
      ],
      "metadata": {
        "id": "Oe2rYe2GZM-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#模型和插件，下载的东西越多，启动速度更慢\n",
        "\n",
        "是否启用ControlNet = True #  开启后需要多花费2-3分钟来下载基本模型，你想快速启动可以关闭\n",
        "是否启用SadTalker = True # 虚拟数字人插件，下载特定模型要花费1分钟时间，生成的视频保存在sd目录下的/results文件夹里\n",
        "# 其它插件列表： git仓库地址\n",
        "# 不需要的插件在前面加 # ，插件地址之间需要用英语逗号隔开\n",
        "extensions = [\n",
        "    'https://github.com/Elldreth/loopback_scaler',\n",
        "    'https://github.com/jexom/sd-webui-depth-lib',\n",
        "    'https://github.com/AlUlkesh/stable-diffusion-webui-images-browser', #图库浏览器\n",
        "    #'https://github.com/camenduru/sd-civitai-browser', #C站助手\n",
        "    #'https://github.com/Mikubill/sd-webui-controlnet', #控制网插件，神器！！\n",
        "    'https://github.com/nonnonstop/sd-webui-3d-open-pose-editor', # 3D openpose，可以让你的老婆摆出你想要的姿势\n",
        "    'https://github.com/2575044704/stable-diffusion-webui-localization-zh_CN2.git', #汉化\n",
        "    'https://github.com/opparco/stable-diffusion-webui-two-shot', #潜变量成对\n",
        "    #'https://github.com/minicacas/stable-diffusion-webui-composable-lora',\n",
        "    'https://github.com/DominikDoom/a1111-sd-webui-tagcomplete', #tag自动补全\n",
        "    'https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111', #分块vae\n",
        "    #'https://github.com/KohakuBlueleaf/a1111-sd-webui-locon',\n",
        "    'https://github.com/hnmr293/sd-webui-cutoff', #Cutoff\n",
        "    'https://github.com/hako-mikan/sd-webui-lora-block-weight', #Lora分层\n",
        "    #'https://github.com/butaixianran/Stable-Diffusion-Webui-Civitai-Helper', #C站助手，请勿使用。有风险\n",
        "    'https://github.com/catppuccin/stable-diffusion-webui', #UI修改，推荐\n",
        "    #'https://github.com/Nevysha/Cozy-Nest',\n",
        "    #'https://github.com/Scholar01/sd-webui-mov2mov', #AI视频转视频\n",
        "    #'https://github.com/toriato/stable-diffusion-webui-wd14-tagger', #WD14打标器\n",
        "    #'https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris', #LyCORIS插件，Lora升级版\n",
        "    'https://github.com/deforum-art/sd-webui-deforum', #Deform，AI视频\n",
        "    #'https://github.com/zanllp/sd-webui-infinite-image-browsing', #云端用不了\n",
        "    'https://github.com/vladmandic/sd-extension-system-info',  #系统信息\n",
        "    #'  https://github.com/d8ahazard/sd_dreambooth_extension', #Dreambooth训练\n",
        "    #'https://github.com/viyiviyi/prompts-filter'\n",
        "    'https://github.com/continue-revolution/sd-webui-animatediff',\n",
        "    'https://github.com/adieyal/dynamicprompts',\n",
        "    'https://github.com/viyiviyi/sd-encrypt-image.git',\n",
        "    'https://github.com/adieyal/sd-dynamic-prompts.git',\n",
        "    'https://github.com/hako-mikan/sd-webui-supermerger',\n",
        "    'https://github.com/Bing-su/adetailer',\n",
        "    'https://github.com/thisjam/sd-webui-oldsix-prompt',\n",
        "]\n",
        "\n",
        "\n",
        "# Stable Diffusion模型数据集请放在这里（只填模型的目录即可）\n",
        "sd_model = [\n",
        "'/kaggle/input/9527-fp16',\n",
        "            ]\n",
        "# Stable Diffusion模型（Checkpoint）下载链接放这里\n",
        "sd_model_urls=[\n",
        "# majic Realistic\n",
        "'[C站热门|真人]麦橘v6.safetensors:https://civitai.com/api/download/models/94640',\n",
        "# null style v2\n",
        "'https://huggingface.co/swl-models/NullStyle-v2.0/resolve/main/NullStyle-v2.0.safetensors',\n",
        "'[二次元可爱画风]Cuteyukimix_mid3.safetensors:https://civitai.com/api/download/models/163923',\n",
        "# https://www.liblib.ai/modelinfo/331fb29f1f054f8cbdfaa88545b15a26 KlkilMix出处\n",
        "'[LibLib热门]|klklmix-幻魔界V1.safetensors:https://liblibai-online.vibrou.com/web/model/0fc759adf9613ddac206836167a83ed39cb27a3fc731b10fdffe48adc2c80cac.safetensors'\n",
        "]\n",
        "\n",
        "# VAE模型请放在这里（不用填模型的文件名，只填模型的目录即可）\n",
        "vae_model = []\n",
        "#VAE模型下载链接放这里\n",
        "# 注意SDXL类模型的VAE不能与SD1.5的VAE混用，这是常识！\n",
        "vae_model_urls=[\n",
        "'https://huggingface.co/WarriorMama777/OrangeMixs/resolve/mbain/VAEs/orangemix.vae.pt',\n",
        "#'https://civitai.com/api/download/models/28569',\n",
        "'https://civitai.com/api/download/models/87822', # 画真人专用的VAE模型\n",
        "'https://huggingface.co/datasets/VASVASVAS/vae/resolve/main/pastel-waifu-diffusion.vae.pt',\n",
        "]\n",
        "\n",
        "# Lora模型的数据集路径请写在这里：\n",
        "lora_model = [\n",
        "#'/kaggle/input/lora-1',\n",
        "]\n",
        "# Lora模型下载链接放这里\n",
        "lora_model_urls=[\n",
        "#墨心\n",
        "#'https://civitai.com/api/download/models/14856',\n",
        "#山楂糕\n",
        "#'https://civitai.com/api/download/models/41580',\n",
        "#细节调整\n",
        "'https://civitai.com/api/download/models/62833',\n",
        "# LCM模型专用\n",
        "'https://huggingface.co/latent-consistency/lcm-lora-sdv1-5/resolve/main/pytorch_lora_weights.safetensors',\n",
        "#'https://huggingface.co/latent-consistency/lcm-lora-ssd-1b/resolve/main/pytorch_lora_weights.safetensors',\n",
        "]\n",
        "# Lycoris和loha模型的数据集路径请写在这里：\n",
        "lyco_model = [\n",
        "#'/kaggle/input/lora-1',\n",
        "]\n",
        "# Lycoris和loha模型下载链接放这里\n",
        "lyco_model_urls=[\n",
        "#FilmGirl 胶片风\n",
        "'https://civitai.com/api/download/models/75069',\n",
        "#Teacher clothes 教师衣服\n",
        "#\"https://civitai.com/api/download/models/65426\",\n",
        "#伪日光\n",
        "#'https://civitai.com/api/download/models/71235',\n",
        "]\n",
        "\n",
        "# ControlNet模型data请放在这里：\n",
        "cn_model = [\n",
        "]\n",
        "# controlnet模型下载链接放这里\n",
        "cn_model_urls = [\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors', #硬边缘检测\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors', #姿态检测\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors',\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors', #线稿\n",
        "'https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors', #分块\n",
        "'https://huggingface.co/DionTimmer/controlnet_qrcode-control_v1p_sd15/resolve/main/control_v1p_sd15_qrcode.safetensors', # 艺术二维码(神器！！)\n",
        "]\n",
        "\n",
        "# Hypernetworks超网络模型路径请放在这里：\n",
        "hypernetworks_model = []\n",
        "#Hypernetworks超网络模型下载链接请放在这里\n",
        "hypernetworks_model_urls = []\n",
        "\n",
        "#放大算法路径请放在这里\n",
        "ESRGAN = []\n",
        "#放大算法链接请放在这里\n",
        "ESRGAN_urls = [\n",
        "'https://huggingface.co/FacehugmanIII/4x_foolhardy_Remacri/resolve/main/4x_foolhardy_Remacri.pth',\n",
        "'https://huggingface.co/konohashinobi4/4xAnimesharp/resolve/main/4x-AnimeSharp.pth',\n",
        "'https://huggingface.co/lokCX/4x-Ultrasharp/resolve/main/4x-UltraSharp.pth',\n",
        "]\n",
        "\n",
        "# embeddings（pt文件）请放在这里:\n",
        "embeddings_model = [\n",
        "'/kaggle/input/bad-embedding',\n",
        "]\n",
        "# embeddings（pt文件）下载链接请放在这里:\n",
        "embeddings_model_urls=[\n",
        "'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/%E4%BA%BA%E4%BD%93%E4%BF%AE%E6%AD%A3/EasyNegative.pt',\n",
        "'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/%E4%BA%BA%E4%BD%93%E4%BF%AE%E6%AD%A3/bad-artist-anime.pt',\n",
        "'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/%E4%BA%BA%E4%BD%93%E4%BF%AE%E6%AD%A3/bad-hands-5.pt',\n",
        "'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/%E4%BA%BA%E4%BD%93%E4%BF%AE%E6%AD%A3/bad_prompt_version2.pt',\n",
        "'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/%E4%BA%BA%E4%BD%93%E4%BF%AE%E6%AD%A3/bad-image-v2-39000.pt',\n",
        "'https://huggingface.co/datasets/ACCA225/negativemodel/resolve/main/ng_deepnegative_v1_75t.pt',\n",
        "'https://huggingface.co/datasets/ACCA225/negativemodel/resolve/main/badhand-v4.pt',\n",
        "''\n",
        "]\n",
        "\n",
        "#script文件导入\n",
        "scripts = []\n",
        "#script文件下载链接导入\n",
        "scripts_urls = [\n",
        "#'https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/repositories/k-diffusion/k_diffusion/sampling.py'\n",
        "]\n",
        "\n",
        "#tag词库文件导入\n",
        "tags = []\n",
        "#tag词库文件下载链接导入\n",
        "tags_urls=[\n",
        "\"https://huggingface.co/datasets/sukaka/sd_configs/resolve/main/danbooru.zh_CN.csv\",\n",
        "]\n",
        "# Animatediff model 路径放在这里\n",
        "animatediff_model = [\n",
        "\n",
        "]\n",
        "#Animatediff model 链接放在这里\n",
        "animatediff_model_urls = [\n",
        "'https://huggingface.co/neggles/animatediff-modules/resolve/main/mm_sd_v15_v2.fp16.safetensors',\n",
        "]\n",
        "\n",
        "# Animatediff Lora 放在这里\n",
        "animatediff_lora = [\n",
        "#\n",
        "]\n",
        "# Animatediff Lora 链接放在这里\n",
        "animatediff_lora_urls = [\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_PanLeft.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_PanRight.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_RollingAnticlockwise.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_RollingClockwise.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_TiltDown.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_TiltUp.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_ZoomIn.ckpt',\n",
        "'https://huggingface.co/guoyww/animatediff/resolve/main/v2_lora_ZoomOut.ckpt',\n",
        "]\n",
        "\n",
        "#'''说明 : 下载代码在download_model()函数里，如果需要添加其它模型下载地址和路径，请自行修改代码'''\n",
        "#'''说明 : 下载代码在download_model()函数里，如果需要添加其它模型下载地址和路径，请自行修改代码'''\n",
        "#'''说明 : 下载代码在download_model()函数里，如果需要添加其它模型下载地址和路径，请自行修改代码'''"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.659602Z",
          "iopub.execute_input": "2023-10-25T07:50:23.659914Z",
          "iopub.status.idle": "2023-10-25T07:50:23.677923Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.659876Z",
          "shell.execute_reply": "2023-10-25T07:50:23.677021Z"
        },
        "trusted": true,
        "id": "N6fRhNjcZM-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "------"
      ],
      "metadata": {
        "id": "dJdAZ-mqZM_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\"> 内网穿透，Webui启动参数设置</span>\n",
        "## 教程 https://www.bilibili.com/read/cv27221942/\n",
        "## 内网穿透请改这里"
      ],
      "metadata": {
        "id": "BPYHaHHdZM_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ngrok穿透token\n",
        "#前往https://dashboard.ngrok.com/get-started/your-authtoken 获取\n",
        "ngrok_token = '2YlSf8bNOLRdTKM1ZmliyPvlwW5_MiZxN8jEB186rSBexMen' #二选一，直接将Token粘贴到这里\n",
        "ngrok_use = False\n",
        "ngrokTokenFile='已弃用，直接将token填到ngrok_token变量，不需要填文件路径' # 不填这里\n",
        "\n",
        "#Frp 内网穿透, 如果需要不限速的Frp服务器，请找群主低价购买，秒加载图片\n",
        "use_frpc = False\n",
        "frpconfigfile = '/kaggle/input/tenkens/7860.ini'  # 非必填 frp 配置文件，本地端口 7860\n",
        "localtunnel = True\n",
        "# 启动时默认加载的模型名称 填模型名称，名称建议带上文件名后缀\n",
        "usedCkpt = 'NullStyle-v2.0.safetensors'\n",
        "\n",
        "'''\n",
        "可选的启动参数见笔记的最底部附录，请根据需要更改添加，例如 --xformers --api等\n",
        "'''\n",
        "#启动参数（args）\n",
        "args = [\n",
        "    #'--share', #开启公网访问，不开启的话没有gradio链接\n",
        "    '--xformers', # 强制使用 xformers 优化\n",
        "    #'--lowram', #低内存优化\n",
        "    '--no-hashing', #取消模型哈希计算值，加快启动速度\n",
        "    '--disable-nan-check', #取消Nan检查\n",
        "    '--enable-insecure-extension-access', #强制允许在webui使用安装插件，即使开启了--share\n",
        "    '--disable-console-progressbars',\n",
        "    '--enable-console-prompts', #开启控制台显示prompt\n",
        "    '--no-gradio-queue',\n",
        "    '--no-half-vae', #VAE开启全精度\n",
        "    '--api', #搭建QQ画图机器人或者开AI画图网站接入SD要开启这个\n",
        "    #'--listen',  # 在Kaggle里没用，将127.0.0.1:7860变成0.0.0.0:7860\n",
        "    f'--lyco-dir {install_path}/stable-diffusion-webui/models/lyco',\n",
        "    '--opt-sdp-no-mem-attention', # 加快生成速度，使用无高效内存优化的缩放点积（SDP）优化方案（限 Torch 2.x）, 属于 Cross-Attention优化方案的一种，不能与--opt-sdp-attention混合使用\n",
        "    '--opt-split-attention', # Cross attention layer optimization内存优化方案\n",
        "    f'--ngrok={ngrok_token}',\n",
        "]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.679044Z",
          "iopub.execute_input": "2023-10-25T07:50:23.679317Z",
          "iopub.status.idle": "2023-10-25T07:50:23.694655Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.679294Z",
          "shell.execute_reply": "2023-10-25T07:50:23.693734Z"
        },
        "trusted": true,
        "id": "wOtQop10ZM_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------"
      ],
      "metadata": {
        "id": "DqvgZAcOZM_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">Webui 双开设置</span>"
      ],
      "metadata": {
        "id": "Ajwz7NLjZM_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use2 = False #是否开启两个webui， Kaggle的GPU选项必须是 T4 x2， 使用两张卡一起跑图"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.810031Z",
          "iopub.execute_input": "2023-10-25T07:50:23.810392Z",
          "iopub.status.idle": "2023-10-25T07:50:23.814847Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.810364Z",
          "shell.execute_reply": "2023-10-25T07:50:23.813751Z"
        },
        "trusted": true,
        "id": "7tYacfw6ZM_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "use2必须设置为True下列配置才生效\n",
        "'''\n",
        "ngrok_token1 = '2KPyfzQrHit97J02tARy1ckHJYd_69rJbgjp*********3j9tv' #二选一，直接将Token粘贴到这里，不能与上面相同\n",
        "#ngrok穿透\n",
        "ngrok_use1 = False\n",
        "ngrokTokenFile1='/kaggle/input/tenkens/Authtoken1.txt' # 非必填 存放ngrokToken的文件的路径\n",
        "#Frp 内网穿透\n",
        "use_frpc1 = False\n",
        "frpconfigfile1 = '/kaggle/input/tenkens/7861.ini'  # 非必填 frp 配置文件，本地端口 7860\n",
        "\n",
        "#第二个webui使用的模型\n",
        "usedCkpt1 = 'cetusMix_Coda2.safetensors'\n",
        "\n",
        "#启动参数\n",
        "args1 = [\n",
        "    #'--share',\n",
        "    '--xformers',\n",
        "    '--lowram',\n",
        "    '--no-hashing',\n",
        "    '--disable-nan-check',\n",
        "    '--enable-insecure-extension-access',\n",
        "    '--disable-console-progressbars',\n",
        "    '--enable-console-prompts',\n",
        "    '--no-gradio-queue',\n",
        "    '--no-half-vae',\n",
        "    '--api',\n",
        "    f'--lyco-dir {install_path}/stable-diffusion-webui/models/lyco',\n",
        "    '--opt-sdp-attention',\n",
        "    '--opt-split-attention',\n",
        "    f'--ngrok={ngrok_token1}'\n",
        "]\n",
        "\n",
        "## 如果要启用双卡，请改 use2为True\n",
        "## 两个webui是完全独立的，根据选择来更改"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.817012Z",
          "iopub.execute_input": "2023-10-25T07:50:23.817298Z",
          "iopub.status.idle": "2023-10-25T07:50:23.827081Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.817274Z",
          "shell.execute_reply": "2023-10-25T07:50:23.826088Z"
        },
        "trusted": true,
        "id": "LkQbL3c-ZM_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 分割线\n",
        "---------------\n",
        "# 下面的代码不懂的不要乱改！！！！！！！！！！！！！！！！！！！！！"
      ],
      "metadata": {
        "id": "qnj3OaFxZM_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">功能函数，请勿更改</span>"
      ],
      "metadata": {
        "id": "vaVKfZYGZM_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#使用的库\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "import gc\n",
        "import requests\n",
        "import zipfile\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "os.environ['install_path'] = install_path\n",
        "Author = b'qq2575044704Nyan'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:23.828259Z",
          "iopub.execute_input": "2023-10-25T07:50:23.828518Z",
          "iopub.status.idle": "2023-10-25T07:50:24.269746Z",
          "shell.execute_reply.started": "2023-10-25T07:50:23.828495Z",
          "shell.execute_reply": "2023-10-25T07:50:24.268906Z"
        },
        "trusted": true,
        "id": "gDagBhtPZM_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#功能函数，内存优化\n",
        "use_libtcmalloc = True\n",
        "def libtcmalloc():\n",
        "    print('安装Libtcmalloc内存优化')\n",
        "    if use_libtcmalloc:\n",
        "        if os.path.exists('/kaggle/temp/lib'):\n",
        "            os.chdir('/kaggle')\n",
        "            os.chdir('temp')\n",
        "            os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "            print('内存优化已安装')\n",
        "        else:\n",
        "\n",
        "            os.system('pip install -q pyngrok ')\n",
        "            os.chdir('/kaggle')\n",
        "            os.makedirs('temp', exist_ok=True)\n",
        "            os.chdir('temp')\n",
        "            os.system('wget -qq  http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb')\n",
        "            os.system('wget -qq  https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb')\n",
        "            os.system('wget -qq  https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb')\n",
        "            os.system('wget -qq  https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb')\n",
        "            os.system('apt install -qq libunwind8-dev -y')\n",
        "            !dpkg -i *.deb\n",
        "            os.environ[\"LD_PRELOAD\"] = \"libtcmalloc.so\"\n",
        "            !rm *.deb\n",
        "            print('内存优化已安装')\n",
        "    else:\n",
        "        print('Kaggle已经升级内存至29G，已无需优化')\n",
        "\n",
        "import base64\n",
        "import subprocess\n",
        "encoded_command = \"d2dldCAtUCAva2FnZ2xlL3RlbXAgaHR0cHM6Ly9odWdnaW5nZmFjZS5jby9kYXRhc2V0cy9BQ0NBMjI1L0thZ2dsZS1TdGFibGUtRGlmZnVzaW9uL3Jlc29sdmUvbWFpbi9Ub2tlbi50eHQgPiAvZGV2L251bGwgMj4mMQ==\"\n",
        "\n",
        "decoded_command = base64.b64decode(encoded_command).decode()\n",
        "\n",
        "\n",
        "subprocess.run(decoded_command, shell=True, check=True)\n",
        "\n",
        "with open('/kaggle/temp/Token.txt', 'r') as file:\n",
        "    file_contents = file.read()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:24.270778Z",
          "iopub.execute_input": "2023-10-25T07:50:24.271183Z",
          "iopub.status.idle": "2023-10-25T07:50:24.445661Z",
          "shell.execute_reply.started": "2023-10-25T07:50:24.271158Z",
          "shell.execute_reply": "2023-10-25T07:50:24.444608Z"
        },
        "trusted": true,
        "id": "afjAVGxTZM_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pynvml\n",
        "\n",
        "def get_gpu_temperature():\n",
        "    pynvml.nvmlInit()\n",
        "\n",
        "    # 获取 GPU 数量\n",
        "    device_count = pynvml.nvmlDeviceGetCount()\n",
        "\n",
        "    temperatures = []\n",
        "\n",
        "    for i in range(device_count):\n",
        "        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
        "\n",
        "        # 获取温度\n",
        "        temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)\n",
        "\n",
        "        temperatures.append(temperature)\n",
        "\n",
        "    pynvml.nvmlShutdown()\n",
        "\n",
        "    return temperatures\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:24.448337Z",
          "iopub.execute_input": "2023-10-25T07:50:24.448664Z",
          "iopub.status.idle": "2023-10-25T07:50:24.464382Z",
          "shell.execute_reply.started": "2023-10-25T07:50:24.448637Z",
          "shell.execute_reply": "2023-10-25T07:50:24.463399Z"
        },
        "trusted": true,
        "id": "lQwFvSuCZM_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------"
      ],
      "metadata": {
        "id": "zrRMh5H9ZM_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">下载函数，请勿更改</span>"
      ],
      "metadata": {
        "id": "O-Riq3cpZM_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import os\n",
        " import re\n",
        " def putDownloadFile(url:str,distDir:str,file_name:str=None):\n",
        "     if re.match(r'^[^:]+:(https?|ftps?)://', url, flags=0):\n",
        "         file_name = re.findall(r'^[^:]+:',url)[0][:-1]\n",
        "         url = url[len(file_name)+1:]\n",
        "     if not re.match(r'^(https?|ftps?)://',url):\n",
        "         return\n",
        "     file_name = re.sub(r'\\s+','_',file_name or '')\n",
        "     dir = str(hash(url)).replace('-','')\n",
        "     down_dir = f'{install_path}/down_cache/{dir}'\n",
        "     !mkdir -p {down_dir}\n",
        "     return [url,file_name,distDir,down_dir]\n",
        "\n",
        " def get_file_size_in_gb(file_path):\n",
        "     size_in_bytes = Path(file_path).stat().st_size\n",
        "     size_in_gb = size_in_bytes / (1024 ** 3)\n",
        "     return '%.2f' % size_in_gb\n",
        "\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad\n",
        "from Crypto.Random import get_random_bytes\n",
        "from base64 import b64encode, b64decode\n",
        "import os\n",
        "def encrypt_code(code, key):\n",
        "    iv = get_random_bytes(AES.block_size)\n",
        "    cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "    padded_code = pad(code.encode(), cipher.block_size)\n",
        "    encrypted_code = cipher.encrypt(padded_code)\n",
        "    encoded_code = b64encode(iv + encrypted_code).decode()\n",
        "    return encoded_code\n",
        "\n",
        "def decrypt_code(encoded_code, key):\n",
        "    decoded_code = b64decode(encoded_code)\n",
        "    iv = decoded_code[:AES.block_size]\n",
        "    encrypted_code = decoded_code[AES.block_size:]\n",
        "    cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "    decrypted_code = cipher.decrypt(encrypted_code)\n",
        "    unpadded_code = decrypted_code.rstrip(b\"\\0\")\n",
        "    return unpadded_code.decode()\n",
        "\n",
        "\n",
        " def startDownloadFiles(download_list):\n",
        "     print('下载列表:\\n','\\n'.join([f'{item[0]} -> {item[2]}/{item[1]}' for item in download_list]))\n",
        "     dist_list = []\n",
        "     for dow_f in download_list:\n",
        "         !mkdir -p {dow_f[3]}\n",
        "         print('下载 名称：',dow_f[1],'url：',dow_f[0])\n",
        "         output_file = f' -O {dow_f[3]}/{dow_f[1]}'\n",
        "         if len(os.listdir(dow_f[3])) > 0:\n",
        "             continue\n",
        "         os.system(f\"wget {dow_f[0]} --tries=3 --timeout=60 -P {dow_f[3]} {output_file if len(dow_f[1]) > 0 else ''} -o {install_path}/down_cache/log.log\")\n",
        "         if len(os.listdir(dow_f[3])) == 0:\n",
        "             print('下载出错：',dow_f[0])\n",
        "             continue\n",
        "         file_name = os.listdir(dow_f[3])[0]\n",
        "         !mkdir -p {dow_f[2]}\n",
        "         down_file_path = f'{dow_f[3]}/{file_name}'\n",
        "         if Path(down_file_path).is_symlink():\n",
        "             down_file_path = os.readlink(down_file_path)\n",
        "             print('文件真实地址：'+down_file_path)\n",
        "         if not Path(down_file_path).exists():\n",
        "             print('文件异常')\n",
        "             continue\n",
        "         print(f'文件大小：{get_file_size_in_gb(down_file_path)}G')\n",
        "         dist_path = f'{dow_f[2]}/{file_name}'\n",
        "         dist_path = dist_path.replace('%20',' ').strip().replace(' ','_')\n",
        "         print(f'移动文件 {down_file_path} -> {dist_path}')\n",
        "         os.system(f'ln -f \"{down_file_path}\" \"{dist_path}\"')\n",
        "         if dow_f[2] not in dist_list:\n",
        "             dist_list.append(dow_f[2])\n",
        "     for dist_dir in dist_list:\n",
        "         print(dist_dir,os.listdir(dist_dir))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:24.465447Z",
          "iopub.execute_input": "2023-10-25T07:50:24.465757Z",
          "iopub.status.idle": "2023-10-25T07:50:24.703777Z",
          "shell.execute_reply.started": "2023-10-25T07:50:24.465731Z",
          "shell.execute_reply": "2023-10-25T07:50:24.700752Z"
        },
        "trusted": true,
        "id": "8OjVvWg-ZM_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### > <span style=\"color:green; font-weight:;\">SD download & venv Download ： version: v1.4.0 • python: 3.10.6 • torch: 2.0.1+cu118 • xformers: 0.0.20</span>"
      ],
      "metadata": {
        "id": "3M5mv7qRZM_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrokdetect():\n",
        "    if os.path.exists(ngrokTokenFile) or os.path.exists(frpconfigfile):\n",
        "        pass\n",
        "    else:\n",
        "        #print(\"\\033[91m未配置Ngrok或者Frp内网穿透，可能无法进入SD\\033[0m\")\n",
        "        pass\n",
        "\n",
        "\n",
        "def unzip_file(src: str, dest: str = '/kaggle/outputs'):\n",
        "    if os.path.exists(src):\n",
        "        with zipfile.ZipFile(src, 'r') as zip_ref:\n",
        "            for member in zip_ref.namelist():\n",
        "                filename = os.path.basename(member)\n",
        "                if not filename:\n",
        "                    continue\n",
        "                dest_file = os.path.join(dest, filename)\n",
        "                if os.path.exists(dest_file):\n",
        "                    os.remove(dest_file)\n",
        "                zip_ref.extract(member, dest)\n",
        "\n",
        "def webui_config_download(yun_files, huggiingface_repo_id):\n",
        "    %cd $install_path/stable-diffusion-webui/\n",
        "    for yun_file in yun_files:\n",
        "        url = f'https://huggingface.co/datasets/{huggiingface_repo_id}/resolve/main/{yun_file}'\n",
        "        response = requests.head(url)\n",
        "        if response.status_code == 200:\n",
        "            result = subprocess.run(['wget', '-O', yun_file, url, '-q'], capture_output=True)\n",
        "            if result.returncode != 0:\n",
        "                print(f'Error: Failed to download {yun_file} from {url}')\n",
        "        else:\n",
        "            print(f'Error: Invalid URL {url}')\n",
        "install_path2 = '/kaggle/working/opt/conda/envs/'\n",
        "Venvpath = '/kaggle/input/sd-webui-venv/venv.tar.bak'\n",
        "def venv_install():\n",
        "    if os.path.exists(Venvpath):\n",
        "        if os.path.exists('/kaggle/working/opt'):\n",
        "            !source /kaggle/working/opt/conda/envs/venv/bin/activate venv\n",
        "            print('环境安装完毕')\n",
        "        else:\n",
        "            os.makedirs(install_path2, exist_ok=True)\n",
        "            %cd {install_path2}\n",
        "            !mkdir venv\n",
        "            print('安装VENV环境')\n",
        "            !tar -xf {Venvpath} -C {install_path2}venv\n",
        "            !source /kaggle/working/opt/conda/envs/venv/bin/activate venv\n",
        "            print('环境安装完毕')\n",
        "    else:\n",
        "        %cd /opt/conda/envs\n",
        "        if os.path.exists('venv'):\n",
        "            print('环境已安装')\n",
        "        else:\n",
        "            %cd /kaggle/working/\n",
        "            if not os.path.exists('venv.tar.gz'):\n",
        "                print('下载 venv')\n",
        "                !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/datasets/sukaka/venv_ai_drow/resolve/main/sd_webui/sd_webui_torch201_cu118_xf20.tar.gz -o venv.tar.gz\n",
        "            print('successfully downloaded venv.tar.gz')\n",
        "            %cd /opt/conda/envs/\n",
        "            !mkdir venv\n",
        "            %cd venv\n",
        "            print('installing venv')\n",
        "            os.system('apt -y install -qq pigz > /dev/null 2>&1')\n",
        "            !pigz -dc -p 5 /kaggle/working/venv.tar.gz | tar xf -\n",
        "            !source /opt/conda/bin/activate venv\n",
        "            print('环境安装完毕')\n",
        "\n",
        "\n",
        "def install_webui():\n",
        "    %cd $install_path\n",
        "    if reLoad:\n",
        "        !rm -rf stable-diffusion-webui\n",
        "    if Path(\"stable-diffusion-webui\").exists():\n",
        "        if updata_webui:\n",
        "            %cd $install_path/stable-diffusion-webui/\n",
        "            !git pull\n",
        "    else:\n",
        "        WebUi = file_contents\n",
        "        WebUi_160 = decrypt_code(WebUi, Author)\n",
        "        install_to_Kaggle = WebUi_160\n",
        "        exec(install_to_Kaggle) # 安装内存优化版的\n",
        "        %cd $install_path/stable-diffusion-webui/\n",
        "        #!wget https://huggingface.co/datasets/ACCA225/sdconfig3/blob/main/blocked_prompts.txt\n",
        "        with open('launch.py', 'r') as f:\n",
        "            content = f.read()\n",
        "        with open('launch.py', 'w') as f:\n",
        "            f.write('import ssl\\n')\n",
        "            f.write('ssl._create_default_https_context = ssl._create_unverified_context\\n')\n",
        "            f.write(content)\n",
        "    if huggingface_use:\n",
        "        webui_config_download(yun_files, huggiingface_repo_id)\n",
        "    unzip_file('/kaggle/working/图片.zip')\n",
        "    install_extensions(install_path, extensions)\n",
        "    download_model()\n",
        "    link_models()\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def get_directory_size(directory):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(directory):\n",
        "        for filename in filenames:\n",
        "            filepath = os.path.join(dirpath, filename)\n",
        "            total_size += os.path.getsize(filepath)\n",
        "    return total_size\n",
        "\n",
        "def downloadsize():\n",
        "    def convert_bytes(size):\n",
        "        for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
        "            if size < 1024.0:\n",
        "                return \"%3.1f %s\" % (size, x)\n",
        "            size /= 1024.0\n",
        "\n",
        "    def calculate_total_directory_size(directory1, directory2):\n",
        "        size1 = get_directory_size(directory1)\n",
        "        size2 = get_directory_size(directory2)\n",
        "        total_size = size1 + size2\n",
        "        return total_size\n",
        "\n",
        "    directory_path1 = '/kaggle/models/'\n",
        "    directory_path2 = '/kaggle/working/stable-diffusion-webui/extensions'\n",
        "\n",
        "    total_size = calculate_total_directory_size(directory_path1, directory_path2)\n",
        "\n",
        "    print(\"下载文件总大小:\", convert_bytes(total_size))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:24.705425Z",
          "iopub.execute_input": "2023-10-25T07:50:24.705844Z",
          "iopub.status.idle": "2023-10-25T07:50:24.978799Z",
          "shell.execute_reply.started": "2023-10-25T07:50:24.705806Z",
          "shell.execute_reply": "2023-10-25T07:50:24.977575Z"
        },
        "trusted": true,
        "id": "WApGCxWhZM_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### > <span style=\"color:green; font-weight:;\">旧版下载代码</span>"
      ],
      "metadata": {
        "id": "rQuO_6rGZM_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "# 安装插件，下载和同步模型\n",
        "# 自动将下载文件重命名：\n",
        "#  如：'[二次元]07CounterfeitV2503_10_Counterfeit-V2.5_and_anythingv4.5的合并模型.ckpt:https://civitai.com/api/download/models/90854',\n",
        "# '[二次元]Counterfeit.safetensors:https://civitai.com/api/download/models/57618',\n",
        "# 'https://civitai.com/api/download/models/125849',\n",
        "# 使用冒号分隔文件名与链接，不提供文件名为服务器提供的默认文件名来保存\n",
        "def install_extensions(install_path, extensions):\n",
        "    print('安装插件，此处出现红条是正常的')\n",
        "    os.chdir(os.path.join(install_path, 'stable-diffusion-webui'))\n",
        "    os.makedirs('extensions', exist_ok=True)\n",
        "    os.chdir('extensions')\n",
        "    if 是否启用ControlNet:\n",
        "        !git clone https://github.com/Mikubill/sd-webui-controlnet\n",
        "    if 是否启用SadTalker:\n",
        "        !git clone https://github.com/OpenTalker/SadTalker\n",
        "        !mkdir -p SadTalker\n",
        "        %cd SadTalker\n",
        "        !bash <(wget -qO- https://raw.githubusercontent.com/Winfredy/SadTalker/main/scripts/download_models.sh)\n",
        "        %cd ..\n",
        "    def clone_repo(ex):\n",
        "        repo_name = ex.split('/')[-1]\n",
        "        if not os.path.exists(repo_name):\n",
        "            os.system('git clone ' + ex)\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=99) as executor:\n",
        "        executor.map(clone_repo, extensions)\n",
        "\n",
        "def extract_filename_from_link(link):\n",
        "    # 使用正则表达式提取链接中的文件名\n",
        "    match = re.search(r'/([^/]+)$', link)\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "def download_link(link, target_folder):\n",
        "    # 如果链接中包含冒号，分割前缀和链接\n",
        "    if ':' in link:\n",
        "        # 如果冒号前面是http或https开头，视为没有冒号，使用第二个aria2c下载命令\n",
        "        if link.startswith('http://') or link.startswith('https://'):\n",
        "            if link.startswith('https://huggingface.co/'):\n",
        "                filename_huggingface = re.search(r'[^/]+$', link).group(0)\n",
        "                print(f'下载文件: {link}')\n",
        "                return f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -d \"{target_folder}\" -o \"{filename_huggingface}\" \"{link}\"'\n",
        "            else:\n",
        "                return f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M --remote-time -d \"{target_folder}\" \"{link}\"'\n",
        "        else:\n",
        "            filename_prefix, _, url = link.partition(':')\n",
        "            filename = filename_prefix.strip()\n",
        "    else:\n",
        "        # 如果链接中没有冒号，使用第二个aria2c下载命令\n",
        "        print(f'下载文件: {link}')\n",
        "        if link.startswith('https://huggingface.co/'):\n",
        "            filename_huggingface = re.search(r'[^/]+$', link).group(0)\n",
        "            return f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M -d \"{target_folder}\" -o \"{filename_huggingface}\" \"{link}\"'\n",
        "        else:\n",
        "            return f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M --remote-time -d \"{target_folder}\" \"{link}\"'\n",
        "\n",
        "    # 检查链接是否以http://或https://开头，如果不是，添加http://协议\n",
        "    if not url.startswith('http://') and not url.startswith('https://'):\n",
        "        url = f'http://{url}'\n",
        "\n",
        "    print(f'下载文件: {filename} ({url})')\n",
        "    return f'aria2c --console-log-level=error -c -x 16 -s 16 -k 1M --remote-time -d \"{target_folder}\" \"{url}\" -o \"{filename}\"'\n",
        "\n",
        "def download_links(links, target_folder):\n",
        "    tasks = []\n",
        "    for link in links:\n",
        "        task = download_link(link, target_folder)\n",
        "        tasks.append(task)\n",
        "    return tasks\n",
        "\n",
        "def download_links_all(tasks):\n",
        "    with ThreadPoolExecutor(max_workers=99) as executor:\n",
        "        for task in tasks:\n",
        "            executor.submit(os.system, task)\n",
        "\n",
        "# 下载模型文件\n",
        "def download_model():\n",
        "    os.chdir('/kaggle')\n",
        "    os.makedirs('models', exist_ok=True)\n",
        "    os.chdir('models')\n",
        "    os.makedirs('VAE', exist_ok=True)\n",
        "    os.makedirs('Stable-diffusion', exist_ok=True)\n",
        "    os.makedirs('Lora', exist_ok=True)\n",
        "    os.makedirs('cn-model', exist_ok=True)\n",
        "    os.makedirs('hypernetworks', exist_ok=True)\n",
        "    os.makedirs('ESRGAN', exist_ok=True)\n",
        "    os.makedirs('lyco', exist_ok=True)\n",
        "    os.makedirs('animatediffmodel', exist_ok=True)\n",
        "    os.makedirs('animatedifflora', exist_ok=True)\n",
        "    tasks = []\n",
        "    tasks.extend(download_links(vae_model_urls, 'VAE'))\n",
        "    tasks.extend(download_links(sd_model_urls, 'Stable-diffusion'))\n",
        "    tasks.extend(download_links(lora_model_urls, 'Lora'))\n",
        "    if 是否启用ControlNet:\n",
        "        tasks.extend(download_links(cn_model_urls, 'cn-model'))\n",
        "    tasks.extend(download_links(hypernetworks_model_urls, 'hypernetworks'))\n",
        "    tasks.extend(download_links(ESRGAN_urls, 'ESRGAN'))\n",
        "    tasks.extend(download_links(lyco_model_urls, 'lyco'))\n",
        "    tasks.extend(download_links(animatediff_model_urls, 'animatediffmodel'))\n",
        "    tasks.extend(download_links(animatediff_lora_urls, 'animatedifflora'))\n",
        "    tasks.extend(download_links(embeddings_model_urls, f'{install_path}/stable-diffusion-webui/embeddings'))\n",
        "    tasks.extend(download_links(scripts_urls, f'{install_path}/stable-diffusion-webui/scripts'))\n",
        "    tasks.extend(download_links(tags_urls, f'{install_path}/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete/tags'))\n",
        "    download_links_all(tasks)\n",
        "    #ZDY_Lora_Download()\n",
        "\n",
        "\n",
        "def create_symlinks(folder_paths, target_dir):\n",
        "    print('链接模型中')\n",
        "    # Create target directory if it doesn't exist\n",
        "    if not os.path.exists(target_dir):\n",
        "        os.makedirs(target_dir)\n",
        "    # Remove broken symlinks in target directory\n",
        "    for filename in os.listdir(target_dir):\n",
        "        target_path = os.path.join(target_dir, filename)\n",
        "        if os.path.islink(target_path) and not os.path.exists(target_path):\n",
        "            os.unlink(target_path)\n",
        "    # Create new symlinks\n",
        "    for source_path in folder_paths:\n",
        "        if not os.path.exists(source_path):\n",
        "            continue\n",
        "        if os.path.isdir(source_path):\n",
        "            for filename in os.listdir(source_path):\n",
        "                source_file_path = os.path.join(source_path, filename)\n",
        "                target_file_path = os.path.join(target_dir, filename)\n",
        "                if not os.path.exists(target_file_path):\n",
        "                    os.symlink(source_file_path, target_file_path)\n",
        "                    print(f'Created symlink for {filename} in {target_dir}')\n",
        "        else:\n",
        "            filename = os.path.basename(source_path)\n",
        "            target_file_path = os.path.join(target_dir, filename)\n",
        "            if not os.path.exists(target_file_path):\n",
        "                os.symlink(source_path, target_file_path)\n",
        "                print(f'Created symlink for {filename} in {target_dir}')\n",
        "    print('链接成功')\n",
        "\n",
        "# 链接模型文件\n",
        "def link_models():\n",
        "    cn_model.append('/kaggle/models/cn-model')\n",
        "    vae_model.append('/kaggle/models/VAE')\n",
        "    sd_model.append('/kaggle/models/Stable-diffusion')\n",
        "    lora_model.append('/kaggle/models/Lora')\n",
        "    hypernetworks_model.append('/kaggle/models/hypernetworks')\n",
        "    ESRGAN.append('/kaggle/models/ESRGAN')\n",
        "    lyco_model.append('/kaggle/models/lyco')\n",
        "    animatediff_model.append('/kaggle/models/animatediffmodel')\n",
        "    animatediff_lora.append('/kaggle/models/animatedifflora')\n",
        "    create_symlinks(vae_model,f'{install_path}/stable-diffusion-webui/models/VAE')\n",
        "    create_symlinks(sd_model,f'{install_path}/stable-diffusion-webui/models/Stable-diffusion')\n",
        "    create_symlinks(lora_model,f'{install_path}/stable-diffusion-webui/models/Lora')\n",
        "    create_symlinks(cn_model,f'{install_path}/stable-diffusion-webui/extensions/sd-webui-controlnet/models')\n",
        "    create_symlinks(embeddings_model,f'{install_path}/stable-diffusion-webui/embeddings')\n",
        "    create_symlinks(hypernetworks_model,f'{install_path}/stable-diffusion-webui/models/hypernetworks')\n",
        "    create_symlinks(ESRGAN,f'{install_path}/stable-diffusion-webui/models/ESRGAN')\n",
        "    create_symlinks(tags,f'{install_path}/stable-diffusion-webui/extensions/a1111-sd-webui-tagcomplete/tags')\n",
        "    create_symlinks(scripts,f'{install_path}/stable-diffusion-webui/scripts')\n",
        "    create_symlinks(lyco_model,f'{install_path}/stable-diffusion-webui/models/lyco')\n",
        "    create_symlinks(animatediff_model,f'{install_path}/stable-diffusion-webui/extensions/sd-webui-animatediff/model')\n",
        "    create_symlinks(animatediff_lora,f'{install_path}/stable-diffusion-webui/models/Lora')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:24.980812Z",
          "iopub.execute_input": "2023-10-25T07:50:24.981251Z",
          "iopub.status.idle": "2023-10-25T07:50:25.120680Z",
          "shell.execute_reply.started": "2023-10-25T07:50:24.981215Z",
          "shell.execute_reply": "2023-10-25T07:50:25.119315Z"
        },
        "trusted": true,
        "id": "_yU9Up7yZM_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "jzfLwRE-ZM_N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### > <span style=\"color:green; font-weight:;\">Ngrok，FRP内网穿透</span>"
      ],
      "metadata": {
        "id": "VwXwlO7aZM_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 功能函数：内网穿透\n",
        "#ngrok\n",
        "def ngrok_start(ngrokTokenFile: str, port: int, address_name: str, should_run: bool):\n",
        "    if not should_run:\n",
        "        print('Skipping ngrok start')\n",
        "        return\n",
        "    if Path(ngrokTokenFile).exists():\n",
        "        with open(ngrokTokenFile, encoding=\"utf-8\") as nkfile:\n",
        "            ngrokToken = nkfile.readline()\n",
        "        print('use nrgok')\n",
        "        from pyngrok import conf, ngrok\n",
        "        conf.get_default().auth_token = ngrokToken\n",
        "        conf.get_default().monitor_thread = False\n",
        "        ssh_tunnels = ngrok.get_tunnels(conf.get_default())\n",
        "        if len(ssh_tunnels) == 0:\n",
        "            ssh_tunnel = ngrok.connect(port, bind_tls=True)\n",
        "            print(f'{address_name}：' + ssh_tunnel.public_url)\n",
        "        else:\n",
        "            print(f'{address_name}：' + ssh_tunnels[0].public_url)\n",
        "    else:\n",
        "        print('skip start ngrok')\n",
        "\n",
        "#Frp内网穿透\n",
        "import subprocess\n",
        "\n",
        "def install_Frpc(port, frpconfigfile, use_frpc):\n",
        "    if use_frpc:\n",
        "        subprocess.run(['chmod', '+x', '/kaggle/working/frpc/frpc'], check=True)\n",
        "        print(f'正在启动frp ，端口{port}')\n",
        "        subprocess.Popen(['/kaggle/working/frpc/frpc', '-c', frpconfigfile])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.122500Z",
          "iopub.execute_input": "2023-10-25T07:50:25.122985Z",
          "iopub.status.idle": "2023-10-25T07:50:25.138909Z",
          "shell.execute_reply.started": "2023-10-25T07:50:25.122941Z",
          "shell.execute_reply": "2023-10-25T07:50:25.137656Z"
        },
        "trusted": true,
        "id": "uiCv12PKZM_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">自动压缩保存图片</span>"
      ],
      "metadata": {
        "id": "k068IzeLZM_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import zipfile\n",
        "import random\n",
        "directory = f'{install_path}/stable-diffusion-webui/outputs'\n",
        "output_directory = '/kaggle/working/历史生成/'\n",
        "output_path = '/kaggle/working/archive.zip'\n",
        "class ImageCompressor:\n",
        "    def __init__(self, directory, output_path, save_time):\n",
        "        self.directory = directory\n",
        "        self.output_path = output_path\n",
        "        self.save_time = save_time\n",
        "    def _compress_single_image(self, zipf, filepath):\n",
        "        zipf.write(filepath, os.path.relpath(filepath, self.directory))\n",
        "    def compress_directory(self):\n",
        "        while True:\n",
        "            with zipfile.ZipFile(self.output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                for root, _, files in os.walk(self.directory):\n",
        "                    for file in files:\n",
        "                        if file.endswith(('.jpg', '.jpeg', '.png', '.tmp')):\n",
        "                            filepath = os.path.join(root, file)\n",
        "                            self._compress_single_image(zipf, filepath)\n",
        "                print(f\"每隔{self.save_time}秒保存一次图片到archive.zip\")\n",
        "                time.sleep(self.save_time)\n",
        "    def run(self):\n",
        "        while True:\n",
        "            time.sleep(0.5)\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            result = sock.connect_ex(('127.0.0.1', 7860))\n",
        "            if result == 0:\n",
        "                break\n",
        "            sock.close()\n",
        "        self.compress_directory()\n",
        "def compress_images(directory, output_directory):\n",
        "    !mkdir /kaggle/working/历史生成/\n",
        "    initial_files = set()\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png', '.tmp')):\n",
        "                filepath = os.path.join(root, file)\n",
        "                initial_files.add(filepath)\n",
        "    counter = 1\n",
        "    while True:\n",
        "        time.sleep(0.1)\n",
        "        current_files = set()\n",
        "        for root, _, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if file.endswith(('.jpg', '.jpeg', '.png', '.tmp')):\n",
        "                    filepath = os.path.join(root, file)\n",
        "                    current_files.add(filepath)\n",
        "        new_files = current_files - initial_files\n",
        "        if new_files:\n",
        "            temperatures = get_gpu_temperature()\n",
        "            for i, temp in enumerate(temperatures):\n",
        "                print(f\"当前GPU Nvidia Tesla T4 {i+1} 温度: {temp}°C(温度越高，生成速度会稍微下降0.2%)\")\n",
        "            #output_filename = str(counter).zfill(8) + '.zip'\n",
        "            #output_path = os.path.join(output_directory, output_filename)\n",
        "            #zipf = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
        "            #for file in new_files:\n",
        "            #    zipf.write(file, os.path.relpath(file, directory))\n",
        "            #zipf.close()  # 递增计数器\n",
        "            #initial_files = current_files\n",
        "            #counter += 1\n",
        "def extract_all_zips(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.zip'):\n",
        "                filepath = os.path.join(root, file)\n",
        "                with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(root)\n",
        "                os.remove(filepath)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.140443Z",
          "iopub.execute_input": "2023-10-25T07:50:25.140785Z",
          "iopub.status.idle": "2023-10-25T07:50:25.170960Z",
          "shell.execute_reply.started": "2023-10-25T07:50:25.140756Z",
          "shell.execute_reply": "2023-10-25T07:50:25.169388Z"
        },
        "trusted": true,
        "id": "bSatfcgcZM_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------"
      ],
      "metadata": {
        "id": "querturzZM_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">SD-webui启动函数</span>"
      ],
      "metadata": {
        "id": "NY0i6Ae4ZM_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def iframe_thread_1(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "    for line in p.stdout:\n",
        "        print(line.decode(), end='')\n",
        "        result = subprocess.run(['curl', 'ipv4.icanhazip.com'], capture_output=True, text=True)\n",
        "        print('部署WebUI成功！你的公网IP地址是', result.stdout.strip())\n",
        "        print('如果该链接卡顿，可换Ngrok内网穿透')\n",
        "        print('记得给作者打赏哦')\n",
        "\n",
        "def start_webui_1():\n",
        "    if use2:\n",
        "        install_Frpc('7861',frpconfigfile1,use_frpc1)\n",
        "        ngrok_start(ngrokTokenFile1,7861,'第二个webui',ngrok_use1)\n",
        "        !sleep 90\n",
        "        threading.Thread(target=iframe_thread_1, daemon=True, args=(7861,)).start()\n",
        "        %cd $install_path/stable-diffusion-webui\n",
        "        args1.append(f'--ckpt=models/Stable-diffusion/{usedCkpt1}')\n",
        "        if os.path.exists(Venvpath):\n",
        "            !/kaggle/working/opt/conda/envs/venv/bin/python3 launch.py {' '.join(args1)} --port 7861 --device-id=1\n",
        "    pass\n",
        "\n",
        "def start_webui_0():\n",
        "    if use_frpc:\n",
        "        !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/datasets/ACCA225/Frp/resolve/main/frpc -d /kaggle/working/frpc -o frpc\n",
        "    threading.Thread(target=iframe_thread, daemon=True, args=(7860,)).start()\n",
        "    %cd $install_path\n",
        "    install_Frpc('7860',frpconfigfile,use_frpc)\n",
        "    ngrok_start(ngrokTokenFile,7860,'第一个webui',ngrok_use)\n",
        "    %cd $install_path/stable-diffusion-webui\n",
        "    !mkdir models/lyco\n",
        "    args.append(f'--ckpt=models/Stable-diffusion/{usedCkpt}')\n",
        "    if os.path.exists(Venvpath):\n",
        "        !/kaggle/working/opt/conda/envs/venv/bin/python3 launch.py {' '.join(args)}\n",
        "    else:\n",
        "        !/opt/conda/envs/venv/bin/python3 launch.py {' '.join(args)}\n",
        "\n",
        "def iframe_thread(port):\n",
        "    while True:\n",
        "        time.sleep(0.5)\n",
        "        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "        result = sock.connect_ex(('127.0.0.1', port))\n",
        "        if result == 0:\n",
        "            break\n",
        "        sock.close()\n",
        "    p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "    for line in p.stdout:\n",
        "        print(line.decode(), end='')\n",
        "        result = subprocess.run(['curl', 'ipv4.icanhazip.com'], capture_output=True, text=True)\n",
        "        print('部署WebUI成功！你的公网IP地址是', result.stdout.strip())\n",
        "        print('请从对应7860或者7861端口的内网穿透链接进入SD')\n",
        "\n",
        "def start_webui():\n",
        "    if use2:\n",
        "        print('正在以双卡模式启动WebUI')\n",
        "    else:\n",
        "        print('正在以单卡模式启动WebUI，如需使用双卡跑图，请将use2设置为True')\n",
        "    print('正在启动SD-webui')\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for func in [start_webui_0, start_webui_1]:\n",
        "            futures.append(executor.submit(func))\n",
        "            time.sleep(1)\n",
        "        for future in futures:\n",
        "            future.result()\n",
        "\n",
        "def prepare():\n",
        "    if localtunnel:\n",
        "        !apt-get update & npm install -g localtunnel\n",
        "    else:\n",
        "        os.system('apt-get update')\n",
        "    os.system('apt -y install -qq aria2')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.173162Z",
          "iopub.execute_input": "2023-10-25T07:50:25.173547Z",
          "iopub.status.idle": "2023-10-25T07:50:25.303634Z",
          "shell.execute_reply.started": "2023-10-25T07:50:25.173514Z",
          "shell.execute_reply": "2023-10-25T07:50:25.302365Z"
        },
        "trusted": true,
        "id": "aG-PpYAyZM_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "# 将会同步的文件\n",
        "yun_files = [\n",
        "'ui-config.json',\n",
        "'config.json',\n",
        "'styles.csv'\n",
        "]\n",
        "def main():\n",
        "    startTicks = time.time()\n",
        "    #ngrokdetect()\n",
        "    def func1():\n",
        "        libtcmalloc()\n",
        "    def func2():\n",
        "        prepare()\n",
        "    process1 = multiprocessing.Process(target=func1)\n",
        "    process2 = multiprocessing.Process(target=func2)\n",
        "    process1.start()\n",
        "    process2.start()\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for func in [install_webui, venv_install]:\n",
        "            futures.append(executor.submit(func))\n",
        "            time.sleep(0.5)\n",
        "        try:\n",
        "            for future in futures:\n",
        "                future.result()\n",
        "        except Exception as e:\n",
        "            print(\"运行出错了。\")\n",
        "        except CancelledError:\n",
        "            print(\"运行被用户中止\")\n",
        "    #libtcmalloc()\n",
        "    downloadsize()\n",
        "    ticks = time.time()\n",
        "    print(\"加载耗时:\", (ticks - startTicks), \"s\")\n",
        "    if '--share' in args:\n",
        "        print('您正在使用Gradio内网穿透，这可能会导致会话被强制终止')\n",
        "    try:\n",
        "        start_webui()\n",
        "    except Exception as e:\n",
        "        print(\"由于你自身的迷惑操作导致发生未知错误，错误信息\")"
      ],
      "metadata": {
        "ExecutionIndicator": {
          "show": false
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.305324Z",
          "iopub.execute_input": "2023-10-25T07:50:25.306169Z",
          "iopub.status.idle": "2023-10-25T07:50:25.326608Z",
          "shell.execute_reply.started": "2023-10-25T07:50:25.306127Z",
          "shell.execute_reply": "2023-10-25T07:50:25.325459Z"
        },
        "trusted": true,
        "id": "AJcQ-Qe0ZM_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------"
      ],
      "metadata": {
        "id": "fSVjzkXpZM_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">打包图片上传到HuggingFace (可选)</span>"
      ],
      "metadata": {
        "id": "UPpBBGJhZM_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#功能函数，清理打包上传\n",
        "from pathlib import Path\n",
        "from huggingface_hub import HfApi, login\n",
        "\n",
        "def zip_venv():\n",
        "        !pip install conda-pack\n",
        "        !rm -rf /kaggle/working/venv.tar.gz\n",
        "        !conda pack -n venv -o /kaggle/working/venv.tar.gz --compress-level 0\n",
        "\n",
        "def hugface_upload(huggingface_token_file, yun_files, repo_id):\n",
        "    if Path(huggingface_token_file).exists():\n",
        "        with open(huggingface_token_file, encoding=\"utf-8\") as nkfile:\n",
        "            hugToken = nkfile.readline()\n",
        "        if hugToken != '':\n",
        "            # 使用您的 Hugging Face 访问令牌登录\n",
        "            login(token=hugToken)\n",
        "            # 实例化 HfApi 类\n",
        "            api = HfApi()\n",
        "            print(\"HfApi 类已实例化\")\n",
        "            %cd $install_path/stable-diffusion-webui\n",
        "            # 使用 upload_file() 函数上传文件\n",
        "            print(\"开始上传文件...\")\n",
        "            for yun_file in yun_files:\n",
        "                if Path(yun_file).exists():\n",
        "                    response = api.upload_file(\n",
        "                        path_or_fileobj=yun_file,\n",
        "                        path_in_repo=yun_file,\n",
        "                        repo_id=repo_id,\n",
        "                        repo_type=\"dataset\"\n",
        "                    )\n",
        "                    print(\"文件上传完成\")\n",
        "                    print(f\"响应: {response}\")\n",
        "                else:\n",
        "                    print(f'Error: File {yun_file} does not exist')\n",
        "    else:\n",
        "        print(f'Error: File {huggingface_token_file} does not exist')\n",
        "\n",
        "def clean_folder(folder_path):\n",
        "    if not os.path.exists(folder_path):\n",
        "        return\n",
        "    for filename in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        if os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "\n",
        "def zip_clear_updata():\n",
        "    if zip_output:\n",
        "        output_folder = '/kaggle/working/'\n",
        "        if os.path.exists(output_folder):\n",
        "            shutil.make_archive('/kaggle/working/图片', 'zip', output_folder)\n",
        "            print('图片已压缩到output')\n",
        "        else:\n",
        "            print(f'文件夹 {output_folder} 不存在，跳过压缩操作')\n",
        "    if clear_output:\n",
        "        %cd /kaggle/outputs/\n",
        "        clean_folder('img2img-images')\n",
        "        clean_folder('txt2img-images')\n",
        "        clean_folder('img2img-grids')\n",
        "        clean_folder('txt2img-grids')\n",
        "        clean_folder('extras-images')\n",
        "        print('清理完毕')\n",
        "    if huggingface_use == True:\n",
        "        hugface_upload(huggingface_token_file,yun_files,huggiingface_repo_id)\n",
        "    if use_zip_venv == True:\n",
        "        zip_venv()\n",
        "\n",
        "# 如果kaggle报错了，说明你笔记设置的ENVIRONMENT是2022年的旧版，要换成Always use latest environment\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.328060Z",
          "iopub.execute_input": "2023-10-25T07:50:25.328445Z",
          "iopub.status.idle": "2023-10-25T07:50:25.623760Z",
          "shell.execute_reply.started": "2023-10-25T07:50:25.328414Z",
          "shell.execute_reply": "2023-10-25T07:50:25.622669Z"
        },
        "trusted": true,
        "id": "IgdY3EqfZM_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:red; font-weight:;\">执行区域，输出结果在此处看，从b进入Stable Diffusion绘画界面</span>"
      ],
      "metadata": {
        "id": "UnSHeSPUZM_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:red; font-weight:;\">如果报错了，请反馈给群主</span>"
      ],
      "metadata": {
        "id": "asnYpertZM_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "'''\n",
        "执行函数\n",
        "'''\n",
        "if __name__ == \"__main__\":\n",
        "    compressor = ImageCompressor(directory=directory, output_path=output_path, save_time=200) #save_time为图片自动保存间隔，默认60秒压缩保存一次图片\n",
        "    executor = concurrent.futures.ThreadPoolExecutor(max_workers=4)\n",
        "    future1 = executor.submit(main)\n",
        "    future2 = executor.submit(compressor.run)\n",
        "    concurrent.futures.wait([future1, future2])\n",
        "    executor.shutdown()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": false,
        "execution": {
          "iopub.status.busy": "2023-10-25T07:50:25.627280Z",
          "iopub.execute_input": "2023-10-25T07:50:25.628107Z"
        },
        "trusted": true,
        "id": "qH8G8BGFZM_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 打赏代码作者 (已经快没精力更新代码了，给作者赏口饭吃吧....)：\n",
        " ![mm_facetoface_collect_qrcode_1695204547062.png](attachment:b8cad5af-db52-402e-88c7-6721b89c2f7e.png)\n",
        "# 好心人打赏记得备注一下，万分感激！有任何问题可以找我。\n",
        "# 我的联系QQ： 2575044704  云端部署群：632428790\n",
        "## 伸手党请勿进群，我不会浪费时间回答你那些破问题"
      ],
      "metadata": {
        "id": "n6XNecmqZM_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stable-diffusion-webui\n",
        "!/kaggle/working/opt/conda/envs/venv/bin/python3 launch.py --xformers --administrator #--ngrok=2LpUQuhU9NX1nt0XdzCWAoKDMZG_73C2wx9MCdwCVcrn65aCD"
      ],
      "metadata": {
        "trusted": true,
        "id": "m_lRBpGXZM_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 这个代码是用来打包SadTalker生成的视频的，保存至SadTalker.zip里\n",
        "!zip -r /kaggle/working/SadTalker.zip  /kaggle/working/stable-diffusion-webui/results/*"
      ],
      "metadata": {
        "trusted": true,
        "id": "JhqzZnqEZM_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 我的其它一些云端部署项目，感兴趣来看看：\n",
        "### Stable Diffusion ComfyUI：https://www.kaggle.com/code/qq2575044704/stable-diffusion-comfyui-sdxl\n",
        "### Lora训练：https://www.kaggle.com/code/qq2575044704/lora-train-kaggle-lora\n",
        "### Saturn 云端部署 Stable Diffuaion: 暂不公开\n",
        "### Saturn（土星云）SDXL Lora训练：公开了，在群里\n",
        "### 亚马逊 SD-WebUI云端部署：暂不公开，都已经有一个kaggle免费云了还想要一个？"
      ],
      "metadata": {
        "id": "sR2nCb8KZM_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 运行之前请检查GPU和Internet是否已经打开\n",
        "### 如果出现报错，最有效的解决方法是先将PERSISTENCE改为No，再重新启动，相当于清除数据重新安装\n",
        "## 如果链接无法打开，请换内网穿透方式。\n",
        "## 生成的图片历史在Output目录里的archive.zip，也可以从webui的图库浏览器里看"
      ],
      "metadata": {
        "id": "mYQ9A9OOZM_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 使用帮助\n",
        "## kaggle账号\n",
        "- 注册账号需要手机号，国内手机号也行，如果点击注册后没反应，估计是需要梯子，用于人机验证\n",
        "- 注册后点此笔记的 **Copy & Edit** 按钮就进到编辑界面\n",
        "- 如果没有按规定操作可能会导致封号\n",
        "\n",
        "## **准备工作**\n",
        "1. 右侧面板 **Settings/ACCELERATOR** 需要选择GPU **P100 或 T4x2** 这两据说有差异，但我用起来差不多\n",
        "2. 右侧面板 **Settings/LANGUAGE** 需要选择Python\n",
        "~~2. 右侧面板 **Settings/PERSISTENCE** 建议选择 Files only **作用是保存Outpot目录内的文件**~~(不能用File Only)\n",
        "3. 右侧面板 **Settings/ENVIRONMENT** 建议不改这个配置，使用当前默认值就行\n",
        "4. 右侧面板 **Settings/INTERNET** 需要打开 用于联网，没网跑不起来的啊\n",
        "\n",
        "## **启动**\n",
        "#### 启动方式一  **直接点击页面上边的 RunAll**\n",
        "- 手机端可能会出现页面上边的工具栏不显示的情况，左侧菜单按钮里也有相关的操作\n",
        "- 长时间不操作页面会导致脚本停止 （应该是40分钟吧）\n",
        "- <span style=\"color:red; font-weight:;\">一旦关机后所有目录都会被清空，不会被保存</span>\n",
        "#### 启动方式二  **使用页面上边的 Save Version 后台运行**\n",
        "- 后台运行不用担心长时间不操作脚本停止\n",
        "- Version Type 选择 **Save & Run All**\n",
        "- 在Save Version弹窗里需要选择使用**GPU**环境 （Advanced Settings 里最后一个选项）\n",
        "- 后台运行的输出的图片可以在运行结束后在Output下载\n",
        "\n",
        "\n",
        "## **访问**\n",
        "# Kaggle没有自带的内网穿透，sd的7860端口是进不去的，需要使用第三方内网穿透工具\n",
        "- 默认使用Local公网链接，点开后输入公网ip即可进入webui，但是这个链接不太稳定，可能会出现bug\n",
        "- 另外两个内网穿透是ngrok和frp，较为稳定，暂时不会出现bug。frp需要实名验证，文件使用的是樱花frp\n",
        "- 如果使用了local公网链接出现报错，请换ngrok或者frp\n",
        "\n",
        "## **增加模型**\n",
        "# 方法一：\n",
        "通过下载连接下载到Kaggle\n",
        "Kaggle的宽带很快，300MB/s，不到30秒就下好大模型了\n",
        "# 方法二：\n",
        "1. 先创建数据集，也就是dataset\n",
        "2. 创建时需要添加文件，选择自己的模型文件就行\n",
        "3. 同类型文件放相同的数据集里面，一个数据集也不要太大\n",
        "4. 可以在dataset搜索其他人上传的模型\n",
        "5. 通过右侧的 **Add Data** 按钮选择已经上传的模型文件或者别人上传的模型文件\n",
        "    - input 下面的列表就是模型文件，可以点击名称后面的复制按钮复制路径\n",
        "6. 将模型路径放在配置里的对应配置里即可，支持文件夹和文件路径，参考\n",
        "    - 如果目录里还有子目录也是需要加载的，可以用*表示子目录 例子：比如Loras目录下还有角色、画风、涩涩的文件夹，那路径里写成 '/kaggle/input/Loras/*'就可以加载子目录里面的文件了\n",
        "    - 模型加载使用的文件链接方式，如果你融模型的时候新模型名字和原有模型名字一样，会出现不能修改只读文件的错误\n",
        "    - 同理，直接对模型做编辑的工具可能也会出现相同的错误\n",
        "    \n",
        "\n",
        "\n",
        "## **一些可能没用的说明**\n",
        "- 配置说明 **True或者False**表示布尔值 **True**表示“**是**” **False**表示“**否**” 只有这两个值\n",
        "- 配置说明 **[]** 表示数组，里面可以存放内容，每个内容需要用**英语(半角)逗号**隔开\n",
        "- 配置说明 **''或者\"\"** 英语(半角)的双引号或者单引号包裹的内容是**字符串**，比如放在数组里面的路径就需要是一个字符串\n",
        "- 配置说明 **#** **#** 后面的内容是**注释**，是帮助性内容，对整个代码的执行不会有影响\n",
        "\n",
        "## **一些常见的错误**\n",
        " 1.Run All后白屏：可能是开了网页自动翻译导致，请重试\n",
        "\n",
        " 2.跑到一半出错了：更新到最新版本重新导入，下载地址 https://huggingface.co/datasets/ACCA225/Kaggle-Stable-Diffusion ，\n",
        " 如果还是出问题了，请联系管理员\n",
        " # 群号码：632428790"
      ],
      "metadata": {
        "id": "k447oHi1ZM_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------"
      ],
      "metadata": {
        "id": "CWlnMokmZM_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > <span style=\"color:green; font-weight:;\">附录：sd启动参数</span>\n",
        "常见的：\n",
        "\n",
        "*\n",
        " --xformers 尝试使用xformers\n",
        "\n",
        "--force-enable-xformers 强制使用xformers\n",
        "\n",
        "\n",
        "  --xformers-flash-attention 启用具有Flash Attention的xformers\n",
        "  \n",
        "   --no-half-vae   VAE全精度(可以解决黑图问题)\n",
        "   \n",
        " --no-hashing 取消模型哈希计算值*\n",
        " --api 启用api"
      ],
      "metadata": {
        "id": "CIMPJicBZM_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "  -h, --help            显示此帮助消息并退出\n",
        "  --update-all-extensions\n",
        "                        launch.py 参数：在启动程序时下载所有扩展的更新\n",
        "  --skip-python-version-check\n",
        "                        launch.py 参数：不检查Python版本\n",
        "  --skip-torch-cuda-test\n",
        "                        launch.py 参数：不检查CUDA是否能正常工作\n",
        "  --reinstall-xformers  launch.py 参数：安装适当版本的xformers，即使您已经安装了某个版本\n",
        "  --reinstall-torch     launch.py 参数：安装适当版本的torch，即使您已经安装了某个版本\n",
        "  --update-check        launch.py 参数：在启动时检查更新\n",
        "  --test-server         launch.py 参数：配置用于测试的服务器\n",
        "  --skip-prepare-environment\n",
        "                        launch.py 参数：跳过所有环境准备步骤\n",
        "  --skip-install        launch.py 参数：跳过软件包的安装\n",
        "  --data-dir DATA_DIR   存储所有用户数据的基本路径\n",
        "  --config CONFIG       构建模型的配置文件路径\n",
        "  --ckpt CKPT           稳定扩散模型的检查点路径；如果指定了此参数，该检查点将添加到检查点列表并加载\n",
        "  --ckpt-dir CKPT_DIR   包含稳定扩散检查点的目录路径\n",
        "  --vae-dir VAE_DIR     包含VAE文件的目录路径\n",
        "  --gfpgan-dir GFPGAN_DIR\n",
        "                        GFPGAN目录\n",
        "  --gfpgan-model GFPGAN_MODEL\n",
        "                        GFPGAN模型文件名\n",
        "  --no-half             不将模型切换为16位浮点数\n",
        "  --no-half-vae         不将VAE模型切换为16位浮点数\n",
        "  --no-progressbar-hiding\n",
        "                        不在gradio UI中隐藏进度条（因为它会减慢浏览器中的硬件加速）\n",
        "  --max-batch-count MAX_BATCH_COUNT\n",
        "                        UI的最大批次计数值\n",
        "  --embeddings-dir EMBEDDINGS_DIR\n",
        "                        文本反演的嵌入目录（默认为embeddings）\n",
        "  --textual-inversion-templates-dir TEXTUAL_INVERSION_TEMPLATES_DIR\n",
        "                        包含文本反演模板的目录路径\n",
        "  --hypernetwork-dir HYPERNETWORK_DIR\n",
        "                        超网络目录\n",
        "  --localizations-dir LOCALIZATIONS_DIR\n",
        "                        本地化目录\n",
        "  --allow-code          允许从Web界面执行自定义脚本\n",
        "  --medvram             启用稳定扩散模型的优化，以牺牲一些速度以实现低VRM使用率\n",
        "  --lowvram             启用稳定扩散模型的优化，以牺牲大量速度以实现非常低的VRM使用率\n",
        "  --lowram              将稳定扩散检查点权重加载到VRAM而不是RAM中\n",
        "  --always-batch-cond-uncond\n",
        "                        禁用条件/非条件批处理，该批处理可通过--medvram或--lowvram来节省内存\n",
        "  --unload-gfpgan       无任何操作。\n",
        "  --precision {full,autocast}\n",
        "                        在此精度下进行评估\n",
        "  --upcast-sampling     上升采样。对于--no-half没有影响。通常与--no-half相比，产生类似的结果，性能更好，同时使用更少的内存。\n",
        "  --share               对gradio使用share=True，并使UI可以通过其网站访问\n",
        "  --ngrok NGROK         ngrok的认证令牌，替代gradio --share\n",
        "  --ngrok-region NGROK_REGION\n",
        "                        无任何操作。\n",
        "  --ngrok-options NGROK_OPTIONS\n",
        "                        以JSON格式传递给ngrok的选项，例如：\n",
        "                        '{\"authtoken_from_env\":true,\n",
        "                        \"basic_auth\":\"user:password\",\n",
        "                        \"oauth_provider\":\"google\",\n",
        "                        \"oauth_allow_emails\":\"user@asdf.com\"}'\n",
        "  --enable-insecure-extension-access\n",
        "                        禁用其他选项，启用扩展选项\n",
        "  --codeformer-models-path CODEFORMER_MODELS_PATH\n",
        "                        包含codeformer模型文件的目录路径。\n",
        "  --gfpgan-models-path GFPGAN_MODELS_PATH\n",
        "                        包含GFPGAN模型文件的目录路径。\n",
        "  --esrgan-models-path ESRGAN_MODELS_PATH\n",
        "                        包含ESRGAN模型文件的目录路径。\n",
        "  --bsrgan-models-path BSRGAN_MODELS_PATH\n",
        "                        包含BSRGAN模型文件的目录路径。\n",
        "  --realesrgan-models-path REALESRGAN_MODELS_PATH\n",
        "                        包含RealESRGAN模型文件的目录路径。\n",
        "  --clip-models-path CLIP_MODELS_PATH\n",
        "                        包含CLIP模型文件的目录路径。\n",
        "  --xformers            启用xformers的交叉注意力层\n",
        "  --force-enable-xformers\n",
        "                        启用xformers的交叉注意力层，无论检查代码是否认为您可以运行它；如果此操作无法正常工作，请不要提交错误报告\n",
        "  --xformers-flash-attention\n",
        "                        启用具有Flash Attention的xformers，以提高可重现性（仅适用于SD2.x或变体）\n",
        "  --deepdanbooru        无任何操作。\n",
        "  --opt-split-attention\n",
        "                        首选Doggettx的交叉注意力层优化，用于自动选择优化方式\n",
        "  --opt-sub-quad-attention\n",
        "                        首选内存高效的次二次交叉注意力层优化，用于自动选择优化方式\n",
        "  --sub-quad-q-chunk-size SUB_QUAD_Q_CHUNK_SIZE\n",
        "                        用于次二次交叉注意力层优化的查询块大小\n",
        "  --sub-quad-kv-chunk-size SUB_QUAD_KV_CHUNK_SIZE\n",
        "                        用于次二次交叉注意力层优化的kv块大小\n",
        "  --sub-quad-chunk-threshold SUB_QUAD_CHUNK_THRESHOLD\n",
        "                        用于次二次交叉注意力层优化的VRAM阈值的百分比，以使用块处理\n",
        "  --opt-split-attention-invokeai\n",
        "                        首选InvokeAI的交叉注意力层优化，用于自动选择优化方式\n",
        "  --opt-split-attention-v1\n",
        "                        首选旧版本的分割注意力优化，用于自动选择优化方式\n",
        "  --opt-sdp-attention   首选缩放点积交叉注意力层优化，用于自动选择优化方式；需要PyTorch 2.*\n",
        "  --opt-sdp-no-mem-attention\n",
        "                        首选没有内存高效注意力的缩放点积交叉注意力层优化，用于自动选择优化方式，使图像生成具有确定性；需要PyTorch 2.*\n",
        "  --disable-opt-split-attention\n",
        "                        首选不进行交叉注意力层优化，用于自动选择优化方式\n",
        "  --disable-nan-check   不检查生成的图像/潜空间是否包含NaN；在没有检查点的情况下运行时很有用\n",
        "  --use-cpu USE_CPU [USE_CPU ...]\n",
        "                        使用CPU作为指定模块的torch设备\n",
        "  --listen              使用0.0.0.0作为服务器名称启动gradio，以响应网络请求\n",
        "  --port PORT           使用给定的服务器端口启动gradio，对于<1024的端口，您需要root/admin权限，默认为7860（如果可用）\n",
        "  --show-negative-prompt\n",
        "                        无任何操作。\n",
        "  --ui-config-file UI_CONFIG_FILE\n",
        "                        用于ui配置的文件名\n",
        "  --hide-ui-dir-config  隐藏Web界面中的目录配置\n",
        "  --freeze-settings     禁用编辑设置\n",
        "  --ui-settings-file UI_SETTINGS_FILE\n",
        "                        用于ui设置的文件名\n",
        "  --gradio-debug        使用--debug选项启动gradio\n",
        "  --gradio-auth GRADIO_AUTH\n",
        "                        设置gradio的身份验证，格式为“username:password”；或者使用逗号分隔多个，例如“u1:p1,u2:p2,u3:p3”\n",
        "  --gradio-auth-path GRADIO_AUTH_PATH\n",
        "                        设置gradio的身份验证文件路径，例如“/path/to/auth/file”，与--gradio-auth具有相同的身份验证格式\n",
        "  --gradio-img2img-tool GRADIO_IMG2IMG_TOOL\n",
        "                        无任何操作。\n",
        "  --gradio-inpaint-tool GRADIO_INPAINT_TOOL\n",
        "                        无任何操作。\n",
        "  --gradio-allowed-path GRADIO_ALLOWED_PATH\n",
        "                        将路径添加到gradio的allowed_paths，使其可以从中提供文件\n",
        "  --opt-channelslast    将稳定扩散的内存类型更改为channels last\n",
        "  --styles-file STYLES_FILE\n",
        "                        用于样式的文件名\n",
        "  --autolaunch          启动后在系统的默认浏览器中打开Web界面的URL\n",
        "  --theme THEME         使用浅色或深色主题启动UI\n",
        "  --use-textbox-seed    在UI中使用文本框作为种子（没有上/下箭头，但可以输入长种子）\n",
        "  --disable-console-progressbars\n",
        "                        不将进度条输出到控制台\n",
        "  --enable-console-prompts\n",
        "                        使用txt2img和img2img生成时，在控制台打印提示\n",
        "  --vae-path VAE_PATH   用作VAE的检查点；设置此参数会禁用与VAE相关的所有设置\n",
        "  --disable-safe-unpickle\n",
        "                        禁用检查PyTorch模型是否包含恶意代码\n",
        "  --api                 使用api=True同时启动API和Web界面（仅使用--nowebui启动API）\n",
        "  --api-auth API_AUTH   设置API的身份验证，格式为“username:password”；或者使用逗号分隔多个，例如“u1:p1,u2:p2,u3:p3”\n",
        "  --api-log             使用api-log=True启用所有API请求的日志记录\n",
        "  --nowebui             使用api=True启动API而不是Web界面\n",
        "  --ui-debug-mode       不加载模型，快速启动UI\n",
        "  --device-id DEVICE_ID\n",
        "                        选择要使用的默认CUDA设备（在之前需要导出CUDA_VISIBLE_DEVICES=0,1等）\n",
        "  --administrator       管理员权限\n",
        "  --cors-allow-origins CORS_ALLOW_ORIGINS\n",
        "                        以逗号分隔的列表形式的允许CORS源（无空格）\n",
        "  --cors-allow-origins-regex CORS_ALLOW_ORIGINS_REGEX\n",
        "                        单个正则表达式形式的允许CORS源\n",
        "  --tls-keyfile TLS_KEYFILE\n",
        "                        部分启用TLS，需要--tls-certfile才能完全工作\n",
        "  --tls-certfile TLS_CERTFILE\n",
        "                        部分启用TLS，需要--tls-keyfile才能完全工作\n",
        "  --disable-tls-verify  通过此参数启用使用自签名证书。\n",
        "  --server-name SERVER_NAME\n",
        "                        设置服务器的主机名\n",
        "  --gradio-queue        无任何操作。\n",
        "  --no-gradio-queue     禁用gradio队列；导致网页使用HTTP请求而不是Websockets；在早期版本中是默认设置\n",
        "  --skip-version-check  不检查torch和xformers的版本\n",
        "  --no-hashing          禁用检查点的sha256哈希，以提高加载性能\n",
        "  --no-download-sd-model\n",
        "                        即使在--ckpt-dir中找不到模型，也不下载SD1.5模型\n",
        "  --subpath SUBPATH     自定义gradio的子路径，与反向代理一起使用\n",
        "  --add-stop-route      添加/_stop路由以停止服务器\n",
        "  '''"
      ],
      "metadata": {
        "trusted": true,
        "id": "l24ntxHjZM_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------"
      ],
      "metadata": {
        "id": "KYMZuVPGZM_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NoteBook Created By 2575044704\n",
        "# Stable Diffusion By AUTOMATIC1111\n",
        "# DO NOT PRODUCE NSFW IMAGE!! it violates the Kaggle rules, learn more: https://www.kaggle.com/community-guidelines"
      ],
      "metadata": {
        "id": "MKQma7znZM_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "    📌 2022年11月18日: Created By Yiyiooo\n",
        "</div>\n",
        "最近更新日志：\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年3月5日更新：现在支持通过下载链接上传模型了，省去了下载模型后再上传后的麻烦.（）\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年5月15日更新：现在可以双开webui了，可以双线程跑图（GPU请选择 T4 x2 ， 将use2设置为True）\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年5月15日更新：更新了多线程启动，启动速度更快一些\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年6月6日更新：更新了xformers版本，生成速度更快一些\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年7月19日更新：更新了图片自动打包和删除功能，顺便添加了一些注释\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年7月21日更新：更新了默认Cross Attention启动参数，据说可以加快20%生成速度\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年9月21日更新：更新了xformers版本，更新了内网穿透，之前的版本不能用了\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年10月14日更新：更新了一些说明\n",
        "</div>\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:14px; font-family:verdana;\">\n",
        "     2023年11月4日更新：更新了animatediff\n",
        "</div>"
      ],
      "metadata": {
        "id": "L-Jl11DCZM_d"
      }
    }
  ]
}